{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.14.0\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names.txt\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of samples: 7944\n Abagael\n Claresta\n Glory\n Liliane\n Prissie\n Geeta\n Giovanne\n Piggy\n"
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "max length: 16\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"263.63625pt\" version=\"1.1\" viewBox=\"0 0 381.65 263.63625\" width=\"381.65pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 263.63625 \nL 381.65 263.63625 \nL 381.65 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 39.65 239.758125 \nL 374.45 239.758125 \nL 374.45 22.318125 \nL 39.65 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 54.868182 239.758125 \nL 67.042727 239.758125 \nL 67.042727 237.837857 \nL 54.868182 237.837857 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 67.042727 239.758125 \nL 79.217273 239.758125 \nL 79.217273 212.267976 \nL 67.042727 212.267976 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 79.217273 239.758125 \nL 91.391818 239.758125 \nL 91.391818 239.758125 \nL 79.217273 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 91.391818 239.758125 \nL 103.566364 239.758125 \nL 103.566364 146.17034 \nL 91.391818 146.17034 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 103.566364 239.758125 \nL 115.740909 239.758125 \nL 115.740909 239.758125 \nL 103.566364 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 115.740909 239.758125 \nL 127.915455 239.758125 \nL 127.915455 49.95482 \nL 115.740909 49.95482 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 127.915455 239.758125 \nL 140.09 239.758125 \nL 140.09 239.758125 \nL 127.915455 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 140.09 239.758125 \nL 152.264545 239.758125 \nL 152.264545 32.672411 \nL 140.09 32.672411 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 152.264545 239.758125 \nL 164.439091 239.758125 \nL 164.439091 239.758125 \nL 152.264545 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 164.439091 239.758125 \nL 176.613636 239.758125 \nL 176.613636 93.514578 \nL 164.439091 93.514578 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 176.613636 239.758125 \nL 188.788182 239.758125 \nL 188.788182 239.758125 \nL 176.613636 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 188.788182 239.758125 \nL 200.962727 239.758125 \nL 200.962727 154.255678 \nL 188.788182 154.255678 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 200.962727 239.758125 \nL 213.137273 239.758125 \nL 213.137273 239.758125 \nL 200.962727 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 213.137273 239.758125 \nL 225.311818 239.758125 \nL 225.311818 204.283705 \nL 213.137273 204.283705 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 225.311818 239.758125 \nL 237.486364 239.758125 \nL 237.486364 239.758125 \nL 225.311818 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 237.486364 239.758125 \nL 249.660909 239.758125 \nL 249.660909 228.034385 \nL 237.486364 228.034385 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 249.660909 239.758125 \nL 261.835455 239.758125 \nL 261.835455 239.758125 \nL 249.660909 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 261.835455 239.758125 \nL 274.01 239.758125 \nL 274.01 237.332524 \nL 261.835455 237.332524 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 274.01 239.758125 \nL 286.184545 239.758125 \nL 286.184545 239.758125 \nL 274.01 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 286.184545 239.758125 \nL 298.359091 239.758125 \nL 298.359091 238.747458 \nL 286.184545 238.747458 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 298.359091 239.758125 \nL 310.533636 239.758125 \nL 310.533636 239.758125 \nL 298.359091 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 310.533636 239.758125 \nL 322.708182 239.758125 \nL 322.708182 239.454925 \nL 310.533636 239.454925 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 322.708182 239.758125 \nL 334.882727 239.758125 \nL 334.882727 239.758125 \nL 322.708182 239.758125 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 334.882727 239.758125 \nL 347.057273 239.758125 \nL 347.057273 239.657058 \nL 334.882727 239.657058 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path clip-path=\"url(#p221c8acb7b)\" d=\"M 347.057273 239.758125 \nL 359.231818 239.758125 \nL 359.231818 239.555992 \nL 347.057273 239.555992 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m700730e539\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.280769\" xlink:href=\"#m700730e539\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(75.099519 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"125.105944\" xlink:href=\"#m700730e539\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(121.924694 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"171.931119\" xlink:href=\"#m700730e539\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(168.749869 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.756294\" xlink:href=\"#m700730e539\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(212.393794 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"265.581469\" xlink:href=\"#m700730e539\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 12 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(259.218969 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"312.406643\" xlink:href=\"#m700730e539\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 14 -->\n      <g transform=\"translate(306.044143 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"359.231818\" xlink:href=\"#m700730e539\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 16 -->\n      <g transform=\"translate(352.869318 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mf149ba75e7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#mf149ba75e7\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(26.2875 243.557344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#mf149ba75e7\" y=\"214.491444\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 250 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(13.5625 218.290663)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#mf149ba75e7\" y=\"189.224764\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 500 -->\n      <g transform=\"translate(13.5625 193.023983)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#mf149ba75e7\" y=\"163.958083\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 750 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(13.5625 167.757302)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#mf149ba75e7\" y=\"138.691403\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1000 -->\n      <g transform=\"translate(7.2 142.490621)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#mf149ba75e7\" y=\"113.424722\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1250 -->\n      <g transform=\"translate(7.2 117.223941)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#mf149ba75e7\" y=\"88.158041\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1500 -->\n      <g transform=\"translate(7.2 91.95726)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#mf149ba75e7\" y=\"62.891361\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1750 -->\n      <g transform=\"translate(7.2 66.690579)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#mf149ba75e7\" y=\"37.62468\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 2000 -->\n      <g transform=\"translate(7.2 41.423899)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 39.65 239.758125 \nL 39.65 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 374.45 239.758125 \nL 374.45 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path d=\"M 39.65 239.758125 \nL 374.45 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 39.65 22.318125 \nL 374.45 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_17\">\n    <!-- Sequence length distribution -->\n    <defs>\n     <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n     <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     <path d=\"M 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\nM 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nL 54.390625 -20.796875 \nL 45.40625 -20.796875 \nz\n\" id=\"DejaVuSans-113\"/>\n     <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n     <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n     <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n    </defs>\n    <g transform=\"translate(120.321875 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-83\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"125\" xlink:href=\"#DejaVuSans-113\"/>\n     <use x=\"188.476562\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"251.855469\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"313.378906\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"376.757812\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"431.738281\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"493.261719\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"525.048828\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"552.832031\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"614.355469\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"677.734375\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"741.210938\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"780.419922\" xlink:href=\"#DejaVuSans-104\"/>\n     <use x=\"843.798828\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"875.585938\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"939.0625\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"966.845703\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"1018.945312\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"1058.154297\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"1099.267578\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"1127.050781\" xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"1190.527344\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"1253.90625\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"1293.115234\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"1320.898438\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"1382.080078\" xlink:href=\"#DejaVuSans-110\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p221c8acb7b\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"39.65\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "n_tokens: 56\n"
    }
   ],
   "source": [
    "tokens = set(''.join(names))### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "tokens.add(pad_token)\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "token_to_id = {token: i for token, i in zip(tokens, range(len(tokens)))}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Abagael\n Glory\n Prissie\n Giovanne\n[[30 45 37 39 23 39 43 38 20]\n [30 48 38  1 11 42 20 20 20]\n [30 28 11  2  0  0  2 43 20]\n [30 48  2  1  5 39  4  4 43]]\n"
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation=keras.activations.relu)### YOUR CODE HERE\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation=keras.activations.softmax)### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb, h_t])### YOUR CODE HERE\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "### YOUR CODE HERE\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m0c6302cfe6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m0c6302cfe6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(42.140057 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"106.254968\" xlink:href=\"#m0c6302cfe6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(96.711218 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"167.188629\" xlink:href=\"#m0c6302cfe6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 400 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(157.644879 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"228.12229\" xlink:href=\"#m0c6302cfe6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 600 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(218.57854 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"289.055951\" xlink:href=\"#m0c6302cfe6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 800 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(279.512201 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"349.989611\" xlink:href=\"#m0c6302cfe6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1000 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(337.264611 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m0d5cfc5f6f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0d5cfc5f6f\" y=\"212.949892\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 216.749111)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0d5cfc5f6f\" y=\"180.665215\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 184.464433)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0d5cfc5f6f\" y=\"148.380537\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 152.179756)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0d5cfc5f6f\" y=\"116.095859\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 2.5 -->\n      <g transform=\"translate(7.2 119.895078)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0d5cfc5f6f\" y=\"83.811182\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 3.0 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(7.2 87.610401)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0d5cfc5f6f\" y=\"51.526504\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 3.5 -->\n      <g transform=\"translate(7.2 55.325723)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0d5cfc5f6f\" y=\"19.241827\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 4.0 -->\n      <g transform=\"translate(7.2 23.041046)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#pe2f1ce8fef)\" d=\"M 45.321307 17.083636 \nL 46.235312 18.598397 \nL 47.453985 21.615248 \nL 48.063322 23.985252 \nL 48.672658 28.432641 \nL 48.977326 31.360897 \nL 49.586663 40.386973 \nL 50.196 55.447446 \nL 50.805336 80.812388 \nL 51.719341 130.950338 \nL 52.328678 150.080632 \nL 52.938014 158.855948 \nL 53.242683 165.625224 \nL 53.547351 164.340535 \nL 53.852019 163.685567 \nL 54.156688 170.101616 \nL 54.461356 169.999358 \nL 54.766024 173.276831 \nL 55.070693 160.136935 \nL 55.375361 169.104158 \nL 55.680029 144.626241 \nL 56.594034 165.485627 \nL 56.898702 164.090844 \nL 57.203371 173.658315 \nL 57.508039 171.452225 \nL 57.812707 175.110936 \nL 58.117376 174.942058 \nL 58.422044 172.356654 \nL 58.726712 175.689309 \nL 59.031381 174.780161 \nL 59.336049 169.582105 \nL 59.640717 171.834679 \nL 59.945385 173.047129 \nL 60.250054 168.614581 \nL 60.554722 169.743216 \nL 60.85939 177.37307 \nL 61.164059 180.268074 \nL 61.773395 166.018994 \nL 62.078064 177.674465 \nL 62.382732 168.142685 \nL 62.6874 172.32294 \nL 62.992068 173.889287 \nL 63.296737 179.41116 \nL 63.601405 179.027729 \nL 63.906073 177.203246 \nL 64.210742 181.43257 \nL 64.51541 178.317656 \nL 64.820078 169.64954 \nL 65.124747 176.970657 \nL 65.429415 175.350783 \nL 65.734083 175.152332 \nL 66.038752 173.504055 \nL 66.34342 173.531926 \nL 66.648088 187.526966 \nL 66.952756 180.705071 \nL 67.257425 178.616625 \nL 67.562093 168.893561 \nL 67.866761 182.087708 \nL 68.17143 157.657937 \nL 68.476098 177.261652 \nL 68.780766 179.519792 \nL 69.085435 179.72768 \nL 69.390103 164.467163 \nL 69.694771 179.376638 \nL 69.999439 177.344852 \nL 70.304108 162.248972 \nL 70.608776 178.852731 \nL 70.913444 173.785343 \nL 71.218113 182.476643 \nL 71.522781 185.147164 \nL 71.827449 184.910211 \nL 72.132118 178.3737 \nL 72.436786 177.12107 \nL 72.741454 179.476349 \nL 73.046123 183.026944 \nL 73.350791 183.837212 \nL 73.655459 183.837027 \nL 73.960127 190.241438 \nL 74.264796 174.034004 \nL 74.569464 176.222698 \nL 74.874132 180.894455 \nL 75.178801 181.680099 \nL 75.483469 187.262457 \nL 75.788137 182.146607 \nL 76.092806 186.661285 \nL 76.702142 176.075758 \nL 77.006811 182.133153 \nL 77.311479 177.414366 \nL 77.616147 189.046768 \nL 77.920815 171.163069 \nL 78.225484 184.094409 \nL 78.530152 183.629694 \nL 78.83482 179.031108 \nL 79.444157 187.285026 \nL 79.748825 183.145158 \nL 80.053494 194.024514 \nL 80.358162 184.550056 \nL 80.66283 183.162647 \nL 80.967498 183.38148 \nL 81.272167 185.081568 \nL 81.576835 192.601097 \nL 81.881503 195.157067 \nL 82.186172 172.413429 \nL 82.49084 170.968182 \nL 83.100177 189.758558 \nL 83.404845 189.867089 \nL 83.709513 163.545677 \nL 84.014182 184.427077 \nL 84.31885 185.505764 \nL 84.623518 193.363873 \nL 84.928186 185.209612 \nL 85.232855 168.358278 \nL 85.537523 188.812956 \nL 85.842191 184.412975 \nL 86.14686 189.603758 \nL 86.451528 179.719744 \nL 87.060865 193.928598 \nL 87.365533 179.785886 \nL 87.670201 188.675345 \nL 87.974869 188.527357 \nL 88.279538 188.766796 \nL 88.584206 193.152845 \nL 88.888874 182.008834 \nL 89.193543 194.17488 \nL 89.498211 172.096463 \nL 89.802879 186.474411 \nL 90.107548 187.385537 \nL 90.412216 186.772773 \nL 90.716884 189.261653 \nL 91.021553 187.909736 \nL 91.326221 182.077378 \nL 91.935557 199.11718 \nL 92.240226 191.151571 \nL 92.544894 196.518236 \nL 92.849562 192.508822 \nL 93.154231 184.070339 \nL 93.458899 187.231068 \nL 93.763567 191.824928 \nL 94.068236 180.044853 \nL 94.372904 187.916163 \nL 94.677572 190.016501 \nL 94.98224 179.325244 \nL 95.286909 187.518869 \nL 95.591577 180.672435 \nL 95.896245 185.166746 \nL 96.200914 192.306615 \nL 96.505582 189.055536 \nL 96.81025 194.571182 \nL 97.114919 190.507748 \nL 97.419587 190.771957 \nL 97.724255 193.63494 \nL 98.028924 190.188512 \nL 98.333592 181.013547 \nL 98.63826 190.632398 \nL 98.942928 193.602889 \nL 99.552265 184.323764 \nL 99.856933 191.332295 \nL 100.161602 186.668167 \nL 100.46627 190.937364 \nL 100.770938 182.938856 \nL 101.075607 190.883821 \nL 101.380275 188.821446 \nL 101.684943 191.23524 \nL 101.989611 195.231515 \nL 102.29428 194.116673 \nL 102.903616 186.505023 \nL 103.208285 194.480415 \nL 103.512953 185.124411 \nL 103.817621 189.242487 \nL 104.12229 185.8003 \nL 104.426958 192.944718 \nL 104.731626 189.204047 \nL 105.340963 196.454949 \nL 105.645631 195.400354 \nL 105.950299 191.192513 \nL 106.254968 193.721911 \nL 106.559636 187.541768 \nL 106.864304 194.083452 \nL 107.168973 190.92922 \nL 107.778309 198.409501 \nL 108.082978 194.302932 \nL 108.387646 192.393994 \nL 108.692314 191.558949 \nL 108.996982 192.379131 \nL 109.301651 182.756362 \nL 109.606319 188.786755 \nL 109.910987 187.058056 \nL 110.215656 197.758481 \nL 110.520324 189.747889 \nL 110.824992 196.905786 \nL 111.129661 190.327178 \nL 111.434329 190.673463 \nL 111.738997 185.146594 \nL 112.348334 193.657039 \nL 112.95767 189.521944 \nL 113.262339 193.215939 \nL 113.567007 187.662284 \nL 113.871675 194.728337 \nL 114.176344 192.951769 \nL 114.481012 197.656054 \nL 114.78568 199.393966 \nL 115.090349 196.418526 \nL 115.395017 198.423987 \nL 115.699685 193.876842 \nL 116.004354 195.232662 \nL 116.309022 200.466141 \nL 116.61369 191.71625 \nL 116.918358 198.697232 \nL 117.223027 191.311913 \nL 117.527695 192.503703 \nL 117.832363 194.419076 \nL 118.137032 200.99432 \nL 118.4417 201.351365 \nL 118.746368 191.367487 \nL 119.051037 196.77738 \nL 119.355705 190.538499 \nL 119.660373 194.067473 \nL 119.965041 199.279123 \nL 120.26971 196.330023 \nL 120.574378 201.730502 \nL 120.879046 195.57763 \nL 121.183715 196.28885 \nL 121.488383 199.272149 \nL 121.793051 191.314006 \nL 122.09772 196.957712 \nL 122.402388 194.588724 \nL 122.707056 189.885324 \nL 123.316393 194.536428 \nL 123.621061 195.384937 \nL 123.925729 191.44486 \nL 124.230398 192.977971 \nL 124.535066 199.731006 \nL 124.839734 193.987606 \nL 125.144403 193.620608 \nL 125.449071 194.136332 \nL 125.753739 199.703458 \nL 126.058408 200.016282 \nL 126.363076 194.356089 \nL 126.667744 204.503181 \nL 126.972412 197.724544 \nL 127.277081 197.573331 \nL 127.581749 193.989415 \nL 127.886417 196.689916 \nL 128.191086 197.336294 \nL 128.495754 192.299025 \nL 128.800422 200.657665 \nL 129.105091 200.800965 \nL 129.409759 195.875029 \nL 129.714427 195.35454 \nL 130.019096 193.728446 \nL 130.323764 197.654838 \nL 130.628432 192.209491 \nL 130.9331 190.727036 \nL 131.237769 200.370911 \nL 131.847105 191.90551 \nL 132.151774 191.448562 \nL 132.456442 192.51889 \nL 132.76111 198.522397 \nL 133.065779 198.332674 \nL 133.675115 187.60738 \nL 133.979783 202.136117 \nL 134.284452 198.988882 \nL 134.893788 206.579249 \nL 135.198457 195.202088 \nL 135.503125 192.953894 \nL 135.807793 196.389923 \nL 136.112462 185.707594 \nL 136.41713 203.218076 \nL 136.721798 201.432464 \nL 137.026467 195.653117 \nL 137.635803 204.566498 \nL 137.940471 203.05036 \nL 138.24514 203.040523 \nL 138.549808 189.409441 \nL 138.854476 199.818324 \nL 139.159145 202.168831 \nL 139.463813 196.420427 \nL 139.768481 197.649765 \nL 140.07315 191.660098 \nL 140.377818 205.415291 \nL 140.682486 200.346964 \nL 140.987154 202.325639 \nL 141.291823 202.790931 \nL 141.596491 197.54442 \nL 141.901159 201.523138 \nL 142.205828 189.342297 \nL 142.510496 207.05621 \nL 142.815164 197.596562 \nL 143.119833 206.83797 \nL 143.424501 201.694664 \nL 143.729169 202.499544 \nL 144.033838 197.90028 \nL 144.338506 188.746506 \nL 144.643174 199.894627 \nL 144.947842 203.004523 \nL 145.252511 195.360829 \nL 145.557179 203.135553 \nL 145.861847 199.048905 \nL 146.166516 201.029566 \nL 146.471184 198.611823 \nL 146.775852 205.604229 \nL 147.080521 200.248917 \nL 147.689857 198.59151 \nL 147.994525 203.218553 \nL 148.299194 204.824249 \nL 148.603862 200.042422 \nL 148.90853 197.103906 \nL 149.213199 199.968905 \nL 149.517867 196.462015 \nL 149.822535 198.111601 \nL 150.127204 197.248076 \nL 150.73654 201.212276 \nL 151.041209 196.984413 \nL 151.345877 202.355774 \nL 151.650545 190.846228 \nL 151.955213 205.75391 \nL 152.259882 201.637842 \nL 152.56455 200.428248 \nL 152.869218 201.979986 \nL 153.173887 199.617079 \nL 153.478555 202.1337 \nL 153.783223 201.36783 \nL 154.087892 196.987446 \nL 154.697228 201.570468 \nL 155.001896 201.809083 \nL 155.306565 201.213808 \nL 155.611233 204.240904 \nL 155.915901 202.209518 \nL 156.22057 201.424605 \nL 156.525238 204.400314 \nL 157.134575 208.258939 \nL 157.743911 200.250264 \nL 158.04858 208.047126 \nL 158.353248 202.663472 \nL 158.657916 210.473727 \nL 158.962584 201.792388 \nL 159.267253 199.517168 \nL 159.571921 206.219417 \nL 159.876589 202.075193 \nL 160.181258 196.321586 \nL 160.485926 202.936009 \nL 160.790594 203.416411 \nL 161.095263 203.606172 \nL 161.399931 200.313658 \nL 161.704599 195.024289 \nL 162.313936 208.880216 \nL 162.618604 194.990729 \nL 162.923272 200.004936 \nL 163.227941 200.718704 \nL 163.532609 203.379842 \nL 163.837277 199.157752 \nL 164.141946 204.094433 \nL 164.446614 202.866565 \nL 164.751282 202.421978 \nL 165.055951 205.560039 \nL 165.360619 205.460367 \nL 165.665287 203.642118 \nL 165.969955 206.557543 \nL 166.274624 203.34585 \nL 166.579292 198.840617 \nL 166.88396 190.931968 \nL 167.188629 203.482469 \nL 167.493297 206.29629 \nL 167.797965 204.530036 \nL 168.102634 201.068075 \nL 168.407302 202.110431 \nL 168.71197 203.745077 \nL 169.016639 200.045432 \nL 169.321307 204.041853 \nL 169.625975 206.031134 \nL 169.930643 205.652367 \nL 170.235312 210.326409 \nL 170.53998 203.362715 \nL 170.844648 202.769433 \nL 171.149317 202.768679 \nL 171.758653 206.997665 \nL 172.063322 205.211622 \nL 172.36799 199.13593 \nL 172.672658 205.459312 \nL 173.281995 198.66933 \nL 173.586663 203.229676 \nL 173.891331 203.843363 \nL 174.196 200.283593 \nL 174.500668 207.719584 \nL 174.805336 198.617835 \nL 175.110005 201.244296 \nL 175.414673 197.541057 \nL 175.719341 208.258308 \nL 176.02401 196.518205 \nL 176.328678 205.810231 \nL 176.633346 201.001671 \nL 177.242683 206.715737 \nL 177.547351 203.130235 \nL 177.852019 192.566867 \nL 178.156688 204.954325 \nL 178.461356 203.807887 \nL 178.766024 203.754683 \nL 179.070693 194.034159 \nL 179.375361 204.790497 \nL 179.680029 200.262872 \nL 179.984697 199.943712 \nL 180.289366 205.64156 \nL 180.594034 200.214956 \nL 180.898702 206.294858 \nL 181.203371 203.915956 \nL 181.508039 197.294975 \nL 181.812707 206.159425 \nL 182.117376 202.596437 \nL 182.422044 202.403882 \nL 182.726712 207.529146 \nL 183.031381 208.062682 \nL 183.336049 204.75345 \nL 183.640717 206.143738 \nL 183.945385 194.216807 \nL 184.554722 206.653058 \nL 184.85939 195.991304 \nL 185.164059 204.266751 \nL 185.468727 200.687738 \nL 185.773395 201.630715 \nL 186.078064 201.986682 \nL 186.6874 206.493224 \nL 186.992068 200.269807 \nL 187.296737 208.799964 \nL 187.601405 210.723196 \nL 187.906073 207.002745 \nL 188.51541 196.693788 \nL 188.820078 210.464983 \nL 189.124747 206.644391 \nL 189.429415 206.832381 \nL 189.734083 201.255304 \nL 190.038752 199.610829 \nL 190.34342 200.655148 \nL 190.648088 200.74128 \nL 190.952756 194.489629 \nL 191.257425 196.538549 \nL 191.562093 207.355018 \nL 191.866761 200.98329 \nL 192.17143 203.961539 \nL 192.476098 201.966323 \nL 192.780766 200.768428 \nL 193.085435 204.633164 \nL 193.390103 205.931686 \nL 193.694771 198.800714 \nL 193.999439 208.419581 \nL 194.304108 201.00916 \nL 194.608776 201.752016 \nL 194.913444 201.78279 \nL 195.218113 203.94753 \nL 195.522781 202.922293 \nL 195.827449 202.66883 \nL 196.132118 205.82086 \nL 196.741454 208.940132 \nL 197.046123 205.941338 \nL 197.350791 209.77099 \nL 197.655459 200.342123 \nL 197.960127 206.673371 \nL 198.264796 204.418034 \nL 198.874132 208.140601 \nL 199.178801 200.811564 \nL 199.483469 198.161918 \nL 199.788137 207.401971 \nL 200.092806 199.853262 \nL 200.397474 203.317455 \nL 200.702142 208.675153 \nL 201.006811 201.572069 \nL 201.311479 204.936521 \nL 201.616147 197.494319 \nL 201.920815 212.168781 \nL 202.225484 207.362454 \nL 202.530152 209.89069 \nL 202.83482 208.278298 \nL 203.139489 207.503144 \nL 203.444157 198.844435 \nL 203.748825 211.71602 \nL 204.053494 206.713705 \nL 204.358162 206.760158 \nL 204.66283 205.842905 \nL 204.967498 209.540611 \nL 205.272167 209.450314 \nL 205.576835 208.74566 \nL 205.881503 200.493374 \nL 206.186172 204.278228 \nL 206.49084 203.274951 \nL 206.795508 207.182168 \nL 207.100177 202.531657 \nL 207.404845 209.260053 \nL 207.709513 205.645317 \nL 208.014182 192.793506 \nL 208.31885 205.798346 \nL 208.623518 202.074993 \nL 208.928186 207.993768 \nL 209.232855 203.480168 \nL 209.537523 205.229333 \nL 209.842191 204.16972 \nL 210.14686 202.500544 \nL 210.451528 202.979476 \nL 210.756196 204.347442 \nL 211.060865 205.070569 \nL 211.365533 207.730768 \nL 211.670201 205.71704 \nL 211.974869 209.155009 \nL 212.279538 205.572208 \nL 212.584206 191.000997 \nL 212.888874 199.472193 \nL 213.193543 200.121827 \nL 213.498211 207.423978 \nL 214.107548 195.315215 \nL 214.412216 207.044149 \nL 214.716884 205.140784 \nL 215.021553 200.676331 \nL 215.326221 198.291756 \nL 215.630889 208.648759 \nL 215.935557 206.458718 \nL 216.240226 206.011314 \nL 216.544894 208.004152 \nL 216.849562 205.215694 \nL 217.154231 205.013725 \nL 217.458899 201.600387 \nL 217.763567 205.37846 \nL 218.068236 201.488777 \nL 218.372904 206.359654 \nL 218.677572 206.146262 \nL 218.98224 207.58402 \nL 219.286909 203.698216 \nL 219.591577 207.910484 \nL 219.896245 208.285826 \nL 220.200914 204.225794 \nL 220.505582 208.990449 \nL 220.81025 203.987448 \nL 221.114919 208.077945 \nL 221.419587 205.065181 \nL 222.028924 202.429968 \nL 222.333592 202.823021 \nL 222.63826 208.664877 \nL 222.942928 201.375442 \nL 223.247597 201.893007 \nL 223.552265 201.01929 \nL 223.856933 195.260087 \nL 224.46627 204.971706 \nL 224.770938 206.153375 \nL 225.075607 204.595725 \nL 225.380275 210.331936 \nL 225.684943 206.490807 \nL 225.989611 204.368117 \nL 226.29428 205.85051 \nL 226.598948 200.650021 \nL 227.208285 209.824263 \nL 227.512953 201.945502 \nL 227.817621 211.103087 \nL 228.12229 205.530073 \nL 228.426958 204.444343 \nL 229.036295 209.891683 \nL 229.340963 212.627708 \nL 229.645631 205.871855 \nL 229.950299 201.942754 \nL 230.254968 202.827878 \nL 230.559636 208.936953 \nL 230.864304 208.846364 \nL 231.168973 206.097924 \nL 231.473641 197.822361 \nL 231.778309 204.600497 \nL 232.082978 208.657519 \nL 232.387646 206.666613 \nL 232.692314 207.048559 \nL 232.996982 209.641884 \nL 233.301651 201.738076 \nL 233.606319 208.722969 \nL 233.910987 202.132253 \nL 234.215656 201.895608 \nL 234.520324 206.516809 \nL 234.824992 207.687178 \nL 235.129661 204.926661 \nL 235.434329 206.535028 \nL 235.738997 202.366381 \nL 236.043666 205.67355 \nL 236.653002 204.679125 \nL 236.95767 208.32776 \nL 237.262339 197.675189 \nL 237.567007 199.766783 \nL 237.871675 210.024407 \nL 238.176344 211.703643 \nL 238.78568 208.209099 \nL 239.090349 198.916343 \nL 239.395017 205.580136 \nL 239.699685 199.034842 \nL 240.004354 211.344057 \nL 240.61369 204.455034 \nL 241.223027 206.958655 \nL 241.527695 207.322043 \nL 241.832363 206.232172 \nL 242.137032 206.505963 \nL 242.4417 207.188126 \nL 242.746368 205.090844 \nL 243.051037 202.171825 \nL 243.355705 203.800074 \nL 243.660373 208.308917 \nL 243.965041 209.804165 \nL 244.26971 204.106694 \nL 244.574378 205.480318 \nL 244.879046 213.361515 \nL 245.183715 202.636062 \nL 245.488383 207.117119 \nL 245.793051 201.709712 \nL 246.09772 212.119588 \nL 246.402388 210.480224 \nL 246.707056 203.460717 \nL 247.011725 202.512598 \nL 247.316393 199.769662 \nL 247.925729 212.743567 \nL 248.230398 210.299053 \nL 248.535066 201.23984 \nL 248.839734 210.731671 \nL 249.144403 196.878083 \nL 249.449071 205.838841 \nL 249.753739 206.463382 \nL 250.058408 207.940126 \nL 250.363076 207.51382 \nL 250.667744 209.557622 \nL 250.972412 204.049057 \nL 251.277081 212.139039 \nL 251.581749 207.252013 \nL 251.886417 204.886012 \nL 252.191086 205.76651 \nL 252.495754 199.178065 \nL 253.105091 214.488757 \nL 253.409759 209.516449 \nL 253.714427 209.403369 \nL 254.019096 198.763321 \nL 254.323764 209.26635 \nL 254.628432 208.642163 \nL 254.9331 207.254584 \nL 255.237769 202.446548 \nL 255.542437 205.914659 \nL 255.847105 206.001338 \nL 256.151774 202.485134 \nL 256.76111 208.627854 \nL 257.065779 205.385626 \nL 257.370447 205.693555 \nL 257.675115 210.019835 \nL 257.979783 211.410469 \nL 258.284452 213.8692 \nL 258.58912 209.613319 \nL 258.893788 209.876781 \nL 259.198457 205.578758 \nL 259.503125 205.417808 \nL 259.807793 208.950662 \nL 260.112462 203.313176 \nL 260.41713 208.975793 \nL 260.721798 202.613948 \nL 261.331135 211.630727 \nL 261.635803 201.995457 \nL 262.24514 203.579001 \nL 262.549808 203.737441 \nL 262.854476 208.023903 \nL 263.159145 201.928045 \nL 263.768481 207.58141 \nL 264.07315 208.823687 \nL 264.377818 202.629781 \nL 264.682486 204.404556 \nL 264.987154 211.068218 \nL 265.291823 203.607788 \nL 265.596491 210.341003 \nL 265.901159 199.965888 \nL 266.205828 203.814899 \nL 266.510496 203.238327 \nL 266.815164 199.70151 \nL 267.119833 194.160825 \nL 267.424501 204.064129 \nL 267.729169 203.252914 \nL 268.033838 199.958399 \nL 268.338506 205.956956 \nL 268.643174 209.65149 \nL 268.947842 206.002993 \nL 269.252511 204.479535 \nL 269.557179 209.25271 \nL 269.861847 202.186704 \nL 270.166516 203.085021 \nL 270.471184 206.334322 \nL 270.775852 206.871922 \nL 271.080521 206.692083 \nL 271.385189 203.815137 \nL 271.689857 211.653403 \nL 271.994525 207.167313 \nL 272.299194 205.768273 \nL 272.603862 206.612801 \nL 272.90853 211.128011 \nL 273.213199 200.303344 \nL 273.517867 203.885606 \nL 273.822535 201.493911 \nL 274.127204 208.262434 \nL 274.431872 196.476425 \nL 274.73654 208.534039 \nL 275.041209 208.738486 \nL 275.345877 205.758382 \nL 275.650545 200.336196 \nL 275.955213 198.098454 \nL 276.259882 210.666767 \nL 276.56455 202.194524 \nL 276.869218 204.175462 \nL 277.173887 209.679046 \nL 277.478555 203.279146 \nL 277.783223 200.632379 \nL 278.087892 202.925102 \nL 278.39256 207.54715 \nL 278.697228 209.168048 \nL 279.001896 206.453345 \nL 279.306565 201.517903 \nL 279.611233 210.798991 \nL 279.915901 211.022889 \nL 280.22057 201.294383 \nL 280.525238 209.111889 \nL 280.829906 208.232353 \nL 281.134575 205.343999 \nL 281.439243 203.960108 \nL 281.743911 211.029986 \nL 282.04858 207.745323 \nL 282.353248 207.662993 \nL 282.657916 202.967638 \nL 282.962584 205.318491 \nL 283.267253 205.136319 \nL 283.571921 210.4786 \nL 283.876589 209.800024 \nL 284.181258 204.041706 \nL 284.485926 209.605761 \nL 284.790594 201.729501 \nL 285.095263 208.242598 \nL 285.399931 203.022881 \nL 285.704599 209.850741 \nL 286.009268 205.315035 \nL 286.313936 206.893398 \nL 286.618604 206.567919 \nL 286.923272 211.80223 \nL 287.227941 207.538937 \nL 287.532609 200.080785 \nL 287.837277 207.019317 \nL 288.141946 203.006132 \nL 288.446614 202.466307 \nL 288.751282 200.847656 \nL 289.055951 202.833644 \nL 289.360619 205.735021 \nL 289.665287 203.209478 \nL 289.969955 207.748287 \nL 290.274624 205.098203 \nL 290.579292 203.968798 \nL 290.88396 210.320121 \nL 291.188629 206.930914 \nL 291.493297 208.34718 \nL 291.797965 207.463642 \nL 292.102634 205.037887 \nL 292.407302 197.342121 \nL 292.71197 212.643025 \nL 293.016639 207.133014 \nL 293.321307 211.416727 \nL 293.625975 211.713403 \nL 293.930643 211.116049 \nL 294.235312 202.050778 \nL 294.53998 206.106583 \nL 294.844648 212.881917 \nL 295.149317 207.152057 \nL 295.758653 204.026181 \nL 296.063322 204.342608 \nL 296.36799 205.212276 \nL 296.672658 211.902725 \nL 296.977326 209.70474 \nL 297.281995 209.392962 \nL 297.586663 206.735327 \nL 297.891331 198.841556 \nL 298.196 198.296382 \nL 299.110005 210.325755 \nL 299.414673 208.269007 \nL 299.719341 204.185107 \nL 300.02401 203.145198 \nL 300.328678 210.100194 \nL 300.633346 209.102252 \nL 300.938014 210.789593 \nL 301.242683 201.824855 \nL 301.547351 199.718098 \nL 301.852019 207.685092 \nL 302.156688 200.310841 \nL 302.461356 207.268054 \nL 302.766024 210.058575 \nL 303.070693 202.530009 \nL 303.375361 204.135428 \nL 303.680029 204.065314 \nL 303.984697 207.615955 \nL 304.594034 202.674141 \nL 304.898702 208.663153 \nL 305.203371 209.818567 \nL 305.508039 207.042509 \nL 305.812707 212.495607 \nL 306.117376 204.935375 \nL 306.422044 208.098074 \nL 306.726712 204.704564 \nL 307.031381 198.770418 \nL 307.640717 213.144541 \nL 307.945385 206.216092 \nL 308.250054 205.488885 \nL 308.554722 205.179563 \nL 308.85939 202.573661 \nL 309.164059 202.664481 \nL 309.468727 210.994894 \nL 309.773395 211.599199 \nL 310.078064 207.484594 \nL 310.382732 206.976744 \nL 310.6874 207.715435 \nL 311.296737 209.686998 \nL 311.601405 208.088098 \nL 311.906073 199.882203 \nL 312.210742 201.651505 \nL 312.820078 211.011089 \nL 313.124747 205.955555 \nL 313.429415 203.41374 \nL 313.734083 207.055972 \nL 314.038752 203.954266 \nL 314.34342 203.204013 \nL 314.648088 210.303218 \nL 314.952756 204.538727 \nL 315.257425 206.382245 \nL 315.562093 204.598019 \nL 315.866761 201.47884 \nL 316.17143 208.839043 \nL 316.476098 209.54369 \nL 317.085435 198.828809 \nL 317.390103 209.66172 \nL 317.694771 201.764231 \nL 317.999439 208.758461 \nL 318.304108 210.002362 \nL 318.608776 206.506933 \nL 318.913444 206.951974 \nL 319.218113 203.481199 \nL 319.522781 205.58955 \nL 319.827449 210.69868 \nL 320.132118 204.481413 \nL 320.436786 207.925363 \nL 320.741454 204.57983 \nL 321.046123 206.178483 \nL 321.350791 203.385738 \nL 321.655459 208.346034 \nL 321.960127 209.218719 \nL 322.264796 204.116585 \nL 322.569464 209.895032 \nL 322.874132 207.043363 \nL 323.178801 201.380615 \nL 323.483469 207.355441 \nL 323.788137 203.617803 \nL 324.092806 206.667329 \nL 324.397474 208.300089 \nL 324.702142 197.167077 \nL 325.006811 207.384776 \nL 325.616147 206.413766 \nL 325.920815 212.554122 \nL 326.530152 202.494864 \nL 326.83482 202.40332 \nL 327.139489 207.491622 \nL 327.444157 205.175776 \nL 327.748825 214.618232 \nL 328.053494 202.405906 \nL 328.358162 210.853357 \nL 328.66283 211.929488 \nL 328.967498 209.090506 \nL 329.272167 211.136177 \nL 329.576835 206.837084 \nL 329.881503 205.947873 \nL 330.186172 209.091675 \nL 330.49084 198.494532 \nL 330.795508 207.542908 \nL 331.100177 210.186566 \nL 331.709513 206.655621 \nL 332.014182 209.978893 \nL 332.623518 207.277199 \nL 332.928186 202.845366 \nL 333.232855 212.360458 \nL 333.537523 210.991992 \nL 333.842191 203.539922 \nL 334.14686 207.410769 \nL 334.451528 204.465072 \nL 334.756196 209.245813 \nL 335.060865 196.014958 \nL 335.670201 208.564952 \nL 335.974869 209.318899 \nL 336.279538 201.711344 \nL 336.584206 209.742872 \nL 336.888874 208.218513 \nL 337.193543 207.962787 \nL 337.498211 208.562781 \nL 337.802879 204.024395 \nL 338.107548 203.11795 \nL 338.412216 197.733227 \nL 339.021553 210.695255 \nL 339.326221 206.411364 \nL 339.630889 209.97867 \nL 339.935557 203.069149 \nL 340.240226 204.538858 \nL 340.544894 214.050747 \nL 340.849562 212.162485 \nL 341.154231 214.756364 \nL 341.458899 212.338267 \nL 341.763567 202.852394 \nL 342.068236 203.030116 \nL 342.677572 210.536337 \nL 342.98224 210.211497 \nL 343.286909 212.535587 \nL 343.591577 209.413706 \nL 343.896245 207.732269 \nL 344.200914 202.752291 \nL 344.505582 206.46312 \nL 344.81025 208.671751 \nL 345.114919 203.611891 \nL 345.419587 204.475786 \nL 345.724255 209.361634 \nL 346.028924 203.92236 \nL 346.333592 206.6705 \nL 346.63826 206.679868 \nL 346.942928 211.897298 \nL 347.247597 204.547886 \nL 347.552265 208.693311 \nL 347.856933 208.86426 \nL 348.161602 203.950355 \nL 348.46627 201.731757 \nL 348.770938 209.936427 \nL 349.075607 206.445155 \nL 349.380275 213.96806 \nL 349.684943 207.965442 \nL 349.684943 207.965442 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 306.5875 29.878125 \nL 357.903125 29.878125 \nQ 359.903125 29.878125 359.903125 27.878125 \nL 359.903125 14.2 \nQ 359.903125 12.2 357.903125 12.2 \nL 306.5875 12.2 \nQ 304.5875 12.2 304.5875 14.2 \nL 304.5875 27.878125 \nQ 304.5875 29.878125 306.5875 29.878125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_15\">\n     <path d=\"M 308.5875 20.298437 \nL 328.5875 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_16\"/>\n    <g id=\"text_14\">\n     <!-- loss -->\n     <defs>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(336.5875 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe2f1ce8fef\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    \n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Jilacea\n Slolie\n Ilyf\n Rudy\n Nannile\n Tonby\n Iriu\n Beese\n SurLia\n Liditxo\n"
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Trumpica\n Trumpoyna\n Trumpency\n Trumpe\n Trumptlenh\n Trumpy\n Trumpoo\n Trumprire\n Trumpebas\n Trumpyneh\n"
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From <ipython-input-27-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\nWARNING:tensorflow:From <ipython-input-27-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5f3812e903bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3499\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3501\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3502\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3010\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3012\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3013\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2935\u001b[0m         expand_composites=True)\n\u001b[1;32m   2936\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3454\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3455\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3456\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 385\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           \u001b[0;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m       \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    448\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    449\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 450\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1752\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1754\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\nBasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell"
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}